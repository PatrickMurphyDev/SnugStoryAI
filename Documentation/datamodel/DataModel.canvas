{
	"nodes":[
		{"id":"b6f1f1426cee58a2","type":"group","x":840,"y":2900,"width":2117,"height":1160,"label":"LangGraph Details"},
		{"id":"0f3227857fd39874","type":"group","x":160,"y":121,"width":1559,"height":1079,"color":"5","label":"Character"},
		{"id":"7a3b7cf8461ecec4","type":"group","x":2440,"y":2080,"width":870,"height":708,"label":"conversation"},
		{"id":"a4615e52002f3d97","type":"group","x":3600,"y":1180,"width":960,"height":580,"label":"RunTest.js"},
		{"id":"9c62fe018614e8c2","type":"group","x":2061,"y":980,"width":459,"height":300,"color":"#a70eaa","label":"Character Relationships"},
		{"id":"5d070184c37f5f67","type":"group","x":2759,"y":1560,"width":396,"height":330,"label":"Data"},
		{"id":"5e49ee45362f9b51","x":3688,"y":1220,"width":355,"height":292,"type":"group","label":"Player Start Game Settings"},
		{"id":"1770c39eb4ee0fde","x":3640,"y":1800,"width":235,"height":180,"type":"group","label":"Day Loop"},
		{"id":"c176ae6d583f6b98","type":"file","file":"Documentation/datamodel/CharModel.png","x":301,"y":-1409,"width":1409,"height":1330},
		{"id":"139aa690cd4a1252","type":"text","text":"\n### **CharacterTrait**\nDefines traits with attributes like\n- id\n- island_id\n- character_id\n- trait_id\n- value\n","x":880,"y":640,"width":250,"height":320,"color":"6"},
		{"id":"f2ce817f7d75bdc4","type":"text","text":"\n### **Personality**\n- Represents character personality data including:\n  - `relationshipStatus` (String): Current relationship status.\n  - `hobbies`, `childhoodMemories`, etc.\n","x":290,"y":176,"width":425,"height":250,"color":"6"},
		{"id":"9645cd0feeca9769","type":"text","text":"\n### **CharacterDetails**\n- Links to detailed character metadata such as:\n  - `traits` (Array): References to [[Trait]]s.\n  - `resources_id`: References [[Resources]].\n  - `behavioral_patterns_id`: References [[BehavioralPatternsModel]].\n  - `special_conditions_id`: References [[SpecialConditionsModel]].\n","x":290,"y":514,"width":425,"height":324,"color":"6"},
		{"id":"273b1f7d6e4f718d","type":"file","file":"Documentation/datamodel/MD/CharacterModel.md","x":-280,"y":-381,"width":400,"height":1004,"color":"6"},
		{"id":"9634ae7be44339cb","type":"file","file":"Documentation/datamodel/MD/BuildingModel.md","x":930,"y":1260,"width":400,"height":400,"color":"4"},
		{"id":"741091ae3f876bf1","type":"text","text":"### Character Relationship","x":2081,"y":1000,"width":419,"height":60,"color":"#a70eaa"},
		{"id":"98ce9de560ab2ec0","type":"file","file":"Documentation/datamodel/MD/IslandPropertyLot.md","x":1580,"y":1370,"width":400,"height":180,"color":"4"},
		{"id":"925850244acc96de","type":"text","text":"## Schema Fields\n### **Character**\n- `island_id` (ObjectId): References the [[IslandModel]].\n- `is_npc` (Boolean): Indicates if the character is non-player.\n- `is_active` (Boolean): Whether the character is active.\n- `name` (Object): Character's full name with:\n  - `first` (String): First name.\n  - `last` (String): Last name.\n- `age` (Number): Character's age.\n- `biologicalGender` (String): Biological gender, defaults to \"female\".","x":1200,"y":176,"width":406,"height":500,"color":"6"},
		{"id":"60576269a50c2a2c","type":"file","file":"Documentation/datamodel/LargerModel.png","x":2240,"y":-1609,"width":2489,"height":1730},
		{"id":"7ccdb3f8a5f0ca04","type":"file","file":"Documentation/datamodel/MD/IslandModel.md","x":3485,"y":400,"width":400,"height":724,"color":"3"},
		{"id":"ea76984f504e1097","type":"text","text":"\n### **Trait**\n- `id`\n- `island_id` \n- `name` (String): Name of the trait.\n- `description` (String): Description\n- `category` (String): E.g., physical, psychological, etc.\n","x":1276,"y":860,"width":330,"height":280,"color":"6"},
		{"id":"75800cb581207bb6","type":"text","text":"### Relationship Event","x":2081,"y":1200,"width":419,"height":60,"color":"#a70eaa"},
		{"id":"9db3c7850f2f3f6c","type":"file","file":"Documentation/datamodel/MD/JobPosition.md","x":1005,"y":2080,"width":400,"height":400,"color":"2"},
		{"id":"9091c222ea3b26e1","type":"text","text":"### Organization","x":1655,"y":2220,"width":250,"height":120,"color":"2"},
		{"id":"31cb95565d2f96e7","type":"text","text":"### Area","x":2220,"y":1430,"width":250,"height":60,"color":"4"},
		{"id":"373c6dfa18143497","type":"text","text":"## character_introduction","x":2574,"y":2360,"width":323,"height":60},
		{"id":"9fcd4bf58f58594a","type":"text","text":"# finalize_characters\n[[/LLM/Prompts/FinalizeCharacters]]","x":3260,"y":1490,"width":320,"height":120},
		{"id":"881bc99aa1283590","type":"text","text":"# START","x":3260,"y":1370,"width":320,"height":60},
		{"id":"1b4a976f2556696c","type":"text","text":"# Character Class","x":2805,"y":1635,"width":296,"height":60},
		{"id":"72112075da4bf5b4","type":"text","text":"# Generate Game State","x":2779,"y":1575,"width":349,"height":50},
		{"id":"6893222499260c20","type":"text","text":"# StoryDetails Class","x":2805,"y":1710,"width":296,"height":60},
		{"id":"a98d952a31012c41","type":"text","text":"# Conversation State","x":2789,"y":1800,"width":330,"height":60},
		{"id":"63cd1551b0cd7638","type":"text","text":"# initialize_story\n[[/LLM/Prompts/GenerateStory]]","x":3260,"y":1670,"width":320,"height":90},
		{"id":"0252b6649a74bb14","type":"text","text":"# Start Conversation","x":2740,"y":2100,"width":314,"height":60},
		{"id":"f8904898612db66b","type":"text","text":"## answer_question","x":2616,"y":2648,"width":281,"height":60},
		{"id":"800ec800cec8c644","type":"text","text":"# LLM Components\n\n# Node: Characters introduce themselves to the User (as Sherlock)\n\ndef character_introduction(state: ConversationState):\n    \"\"\"\n    Part of the Conversation Sub-Graph.\n\n    Generates and displays a character's introduction to Sherlock Holmes in the murder mystery game.\n\n    Args:\n        state (ConversationState): The LangGraph State object containing:\n            - messages: List of previous conversation messages. Used to store conversation history\n            - character: Character object with persona and character details\n            - story_details: Object containing crime details including:\n                - victim_name, time_of_death, location_found\n                - murder_weapon, cause_of_death\n                - crime_scene_details, initial_clues\n\n    Returns:\n        dict: Adds the introduction messages to the conversation history\n            - messages: Introduction messages to be added\n\n    Note:\n        The function uses an LLM to generate appropriate character dialogue while ensuring\n        the character doesn't reveal their role or incriminate themselves.\n    \"\"\"\n\n    character = state['character']\n    story = state['story_details']\n    character_instructions = \"\"\"You are playing the role of a character with the below persona:\n{subject_persona}\nYou are being interviewed by Sherlock Holmes in relationship to the below crime:\nCrime details:\n- Victim: {victim}\n- Time of death: {time}\n- Location: {location}\nPlease greet and introduce your self to Sherlock Holmes.\nYour tone should be conversational and should address Sherlock Holmes directly.\nMake sure that you do not reveal your role and incriminate yourself.\n\"\"\"\n    system_message = character_instructions.format(\n        subject_persona=character.persona,\n        victim=story.victim_name,\n        time=story.time_of_death,\n        location=story.location_found,\n    )\n    # Generate narration\n    narration = llm.invoke([\n        SystemMessage(content=system_message),\n        HumanMessage(content=\"Introduce yourself to Sherlock Holmes\")\n    ])\n\n    print_introduction(character, narration)\n\n    return {\"messages\": [narration]}\n\n\nsherlock_ask_prompt = \"\"\"\nYou are Sherlock Holmes, the renowned detective. You are interviewing {character_name} about the murder of {victim_name}.\nThe murder occurred around {time_of_death} at {location_found}. The murder weapon was {murder_weapon}, and the cause of death was {cause_of_death}.\n\nHere's the crime scene description: {crime_scene_details}\nHere are some initial clues: {initial_clues}\n\nHere's the conversation history with {character_name}:\n{conversation_history}\n\nConsidering the above information, formulate a insightful and relevant question to ask {character_name} to further investigate the case.\nThe question should be phrased in a manner befitting Sherlock Holmes's inquisitive nature.\nin your answer make a new line for every sentance to make it easier to read.\n\"\"\"\ndef get_question(state: ConversationState):\n    \"\"\"\n    Part of the Conversation Sub-Graph.\n\n    Generates an investigative question from Sherlock Holmes to ask a character.\n\n    Args:\n        state (ConversationState): The LangGraph State object containing:\n            - messages: List of previous conversation messages. Used to store conversation history\n            - character: Character object with persona and character details specific to the character being interviewed\n            - story_details: Object containing crime details including:\n                - victim_name, time_of_death, location_found\n                - murder_weapon, cause_of_death\n                - crime_scene_details, initial_clues\n\n    Returns:\n        str: Generated question content from Sherlock AI assistance.\n\n    Note:\n        The question is generated considering:\n        - The crime scene details and initial clues\n        - Previous conversation history with the character\n        - Sherlock Holmes' characteristic investigative style\n    \"\"\"\n\n    messages = state[\"messages\"]\n    character = state[\"character\"]\n    story = state[\"story_details\"]\n    system_message = sherlock_ask_prompt.format(\n        character_name=character.name,\n        victim_name=story.victim_name,\n        time_of_death=story.time_of_death,\n        location_found=story.location_found,\n        murder_weapon=story.murder_weapon,\n        cause_of_death=story.cause_of_death,\n        crime_scene_details=story.crime_scene_details,\n        initial_clues=story.initial_clues,\n        conversation_history=\"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in messages])\n    )\n\n    prompt = ChatPromptTemplate.from_messages(\n          [\n              (\n                  \"system\",\n                  system_message,\n              ),\n              MessagesPlaceholder(variable_name=\"messages\"),\n          ]\n      )\n    chain = prompt | llm\n    question = chain.invoke(messages)\n\n    console = Console()\n    console.print(Panel(\n        f\"[italic]{question.content}[/italic]\",\n        border_style=\"yellow\",\n        padding=(1, 1),\n        title=\"üîç Asked by Sherlock AI ü§ñüïµÔ∏è\",\n        title_align=\"left\"\n    ))\n\n    return question.content\n\n# Node: User can ask a question to the Character or decide to quit the conversation\n\ndef ask_question(state: ConversationState):\n    \"\"\"\n    Part of the Conversation Sub-Graph.\n\n    Handles the question-asking process, allowing either AI-generated Sherlock questions\n    or direct player input.\n\n    Args:\n        state (ConversationState): The LangGraph State object containing:\n            - messages: List of previous conversation messages. Used to store conversation history\n            - character: Character object with persona and character details\n            - story_details: Object containing crime details including:\n                - victim_name, time_of_death, location_found\n                - murder_weapon, cause_of_death\n                - crime_scene_details, initial_clues\n\n    Returns:\n        dict: Adds question asked to the conversation history\n            - messages : Question to be added\n\n    Note:\n        - Provides option to use AI-generated \"SherlockAI\" questions\n        - Handles input validation and error cases\n        - Allows for conversation termination\n    \"\"\"\n    character = state['character']\n    # Get user input\n    while True:\n      try:\n        use_ai_sherlock = get_player_yesno_answer(\"Do you want SherlockAI to ask a question?\")\n        if use_ai_sherlock.lower()[0] == 'y':\n          question = get_question(state)\n        else:\n          question = get_player_input(character.name)\n        return {\"messages\": [HumanMessage(content=question)]}\n      except ValueError:\n            print(\"Invalid input. Please enter a valid question\")\n\n\n# Node: Character answers the question posed by the User\n\ndef answer_question(state: ConversationState):\n    \"\"\"\n    Part of the Conversation Sub-Graph.\n\n    Generates a character's response to a question during the investigation.\n\n    Args:\n        state (ConversationState): The LangGraph State object containing:\n            - messages: List of previous conversation messages. Used to store conversation history\n            - character: Character object with persona and character details specifc to the character answering the question\n            - story_details: Object containing crime details including:\n                - victim_name, time_of_death, location_found\n                - murder_weapon, cause_of_death\n                - crime_scene_details, initial_clues\n\n    Returns:\n        dict: Adds response from the character to the conversation history\n            - messages : Response to be added\n\n    Note:\n        The character's response:\n        - Maintains consistency with their persona and knowledge\n        - Considers their relationships with other characters\n        - May include deception based on character motivations\n        - Takes into account all previous conversation context\n    \"\"\"\n    messages = state['messages']\n    character = state['character']\n    last_message = messages[-1]\n    story = state['story_details']\n    answer_instructions = \"\"\"\nYou are playing the role of a character with the below persona:\n{subject_persona}\nYou are being interviewed by Sherlock Holmes in relationship to the below crime:\nCrime Scene Details:\n    Victim: {victim}\n    Time: {time}\n    Location: {location}\n    Weapon: {weapon}\n    Cause of Death: {cause}\n\n    Scene Description:\n    {scene}\n\n    All Characters and their relationships:\n    {npc_brief}\nBased on the message history, answer the question as the character would, based on:\n1. Your character's personality and background\n2. Your knowledge of the crime\n3. Your relationships with other characters\n4. Your potential motives or alibis\n\n\nImportant:\n- Stay in character\n- Only reveal information this character would know\n- Maintain consistency with the story details\n- You can lie if your character would have a reason to do so\n\nQuestion to answer:\n{question}\n\"\"\"\n    system_message = answer_instructions.format(\n        subject_persona=character.persona,\n        victim=story.victim_name,\n        time=story.time_of_death,\n        location=story.location_found,\n        weapon=story.murder_weapon,\n        cause=story.cause_of_death,\n        scene=story.crime_scene_details,\n        npc_brief=story.npc_brief,\n        question=last_message.content\n    )\n\n    prompt = ChatPromptTemplate.from_messages(\n          [\n              (\n                  \"system\",\n                  system_message,\n              ),\n              MessagesPlaceholder(variable_name=\"messages\"),\n          ]\n      )\n    chain = prompt | llm\n    answer = chain.invoke(messages)\n\n    print_character_answer(character, answer.content)\n\n    return {\"messages\":[answer]}\n\n# Conditional Edge Function\n\ndef where_to_go(state: ConversationState):\n    \"\"\"\n    Part of the Conversation Sub-Graph.\n\n    Determines the next conversation state based on the last message.\n\n    Args:\n        state (ConversationState): The LangGraph State object containing:\n            - messages: List of previous conversation messages. Used to store conversation history\n            - character: Character object with persona and character details\n            - story_details: Object containing crime details including:\n                - victim_name, time_of_death, location_found\n                - murder_weapon, cause_of_death\n                - crime_scene_details, initial_clues\n\n    Returns:\n        str: Either \"end\" to terminate conversation or \"continue\" to proceed\n\n    Note:\n        Checks for \"EXIT\" keyword in the last message to determine conversation flow.\n    \"\"\"\n    messages = state['messages']\n    last_message = messages[-1]\n    if \"EXIT\" in last_message.content:\n        return \"end\"\n    else:\n        return \"continue\"\n\n\n# Node: Character Creation\n\ncharacter_instructions=\"\"\"You are an AI character designer tasked with creating personas for a murder mystery game.\nYour goal is to develop a cast of characters that fits the given environment and creates an engaging, interactive experience for players.\n\nFirst, carefully understand the environment setting:\n\n\n{{environment}}\n\n\nNow, follow these steps to create the character personas:\n\n1. Review the environment and identify the most interesting themes and elements that could influence character creation.\n\n2. Determine the number of characters to create. This will be specified by the max_characters variable:\n\n\n{{max_characters}}\n\n\n3. Based on the environment and the number of characters, create a list of roles that would be appropriate for the setting. Remember:\n   - One character must be designated as the killer.\n   - One character must be designated as the victim.\n   - The remaining characters should be supporting roles who can be questioned by the detective.\n   - Roles should fit the story setting (e.g., shopkeepers in a market, passengers on a train).\n\n4. Assign one character to each role, ensuring a diverse and interesting cast.\n\n5. For each character, provide:\n   - A name\n   - Their role in the story\n   - A brief description of their persona, including any relevant background or motivations\n\nBefore creating the final list, brainstorm and plan your approach inside  tags:\n\n\n[Your thought process here. Consider the following:\n1. List potential character archetypes that fit the environment.\n2. Brainstorm possible motives for the killer and how other characters might be connected.\n3. Consider character relationships and potential conflicts.\n4. Think about the setting, interesting character dynamics, and how each character might contribute to the mystery.]\n\n\nAfter your brainstorming, create the final list of characters.\n\nRemember:\n- Ensure that the characters and their roles are appropriate for the given environment.\n- Make the characters diverse and interesting to enhance the gameplay experience.\n- Provide enough detail for each character to make them memorable and useful in the game context.\"\"\"\n\ndef create_characters(state: GenerateGameState):\n    \"\"\"\n    Part of the Game Loop Graph.\n\n    Creates a cast of characters for the murder mystery game based on the environment and the max_characters.\n\n    Args:\n        state (GenerateGameState): The LangGraph State object containing:\n            - environment: Description of the game's setting\n            - max_characters: Maximum number of characters to create\n\n    Returns:\n        dict : Contains the generated character list. Adds to the State object.\n            - characters : List of NPC objects with defined roles, including:\n                - One killer\n                - One victim\n                - Supporting characters\n\n    Note:\n        - Uses structured LLM output to ensure consistent character creation\n        - Each character has a name, role, and detailed persona\n        - Ensures character diversity and setting appropriateness\n    \"\"\"\n\n    environment = state['environment']\n    max_characters = state['max_characters']\n\n    # Enforce structured output\n    structured_llm = llm.with_structured_output(NPC)\n\n    # System message\n    system_message = character_instructions.replace(\"{{environment}}\", environment)\n    system_message = system_message.replace(\"{{max_characters}}\", str(max_characters))\n\n    # Generate characters\n    result = structured_llm.invoke([\n        SystemMessage(content=system_message),\n        HumanMessage(content=\"Generate the set of characters\")\n    ])\n\n    # Return the characters from the NPC object\n    return {\"characters\": result.characters}\n\n\n# Node: Story Creation including Crime Seen, Incident Details and Story Arc\n\nstory_instructions = \"\"\"You are crafting the central murder mystery for our story. Using the provided environment and characters, create a compelling murder scenario.\nInclude specific details about the crime while maintaining mystery about the killer's identity.\n\nEnvironment:\n{{environment}}\n\nCharacters:\n{{characters}}\n\nFollow these guidelines when creating the murder scenario:\n\n1. For the victim describe:\n   - Where and how the body was found\n   - The approximate time of death\n   - The cause of death and murder weapon\n   - The condition of the crime scene\n\n2. Include crucial evidence and clues:\n   - Physical evidence at the scene\n   - Witness statements or last known sightings\n   - Any suspicious circumstances\n   - Environmental factors that might be relevant\n\n3. Create a mix of:\n   - True clues that lead to the killer\n   - Red herrings that create suspense\n   - Background circumstances that add depth\n\n4. Consider:\n   - The timing of the murder\n   - Access to the location\n   - Potential motives\n   - Physical evidence\n   - Witness reliability\n\n5. For the Character Brief:\n   - Mention the important points\n   - DO not mention who the killer is\n\nImportant:\n- DO NOT reveal or hint at the killer's identity\n- Include enough detail to make the mystery solvable\n- Ensure all clues are consistent with the environment and characters\n- Make the scenario complex enough to be interesting but clear enough to be solvable\n\nFormat your response to provide the specific details requested in the StoryDetails schema.\"\"\"\n\ndef create_story(state: GenerateGameState):\n    \"\"\"\n    Part of the Game Loop Graph.\n\n    Generates the complete murder mystery scenario and storyline based on the provided environment and the generated characters.\n\n    Args:\n        state (GenerateGameState): The LangGraph State object containing:\n            - environment: Description of the game's setting\n            - characters: List of character objects generated in create_character step\n\n    Returns:\n        dict: Contains the complete story details. Adds to the State Object.\n            - story_details: StoryDetails object including:\n                - Crime scene information\n                - Evidence and clues\n                - Character relationships\n                - Environmental factors\n\n    Note:\n        - Creates a solvable mystery without revealing the killer\n        - Includes both true clues and red herrings\n        - Ensures consistency between characters and environment\n    \"\"\"\n\n    environment = state['environment']\n    characters = state['characters']\n\n    # Format character list for the prompt\n    character_list = \"\\n\".join([char.persona for char in characters])\n\n    # Enforce structured output\n    structured_llm = llm.with_structured_output(StoryDetails)\n\n    # System message\n    system_message = story_instructions.replace(\"{{environment}}\", environment)\n    system_message = system_message.replace(\"{{characters}}\", character_list)\n\n    # Generate story details\n    result = structured_llm.invoke([\n        SystemMessage(content=system_message),\n        HumanMessage(content=\"Generate the murder mystery scenario\")\n    ])\n\n    # Return the story details\n    return {\"story_details\": result}\n\n\n# Node: The Narator (Dr. John Watson) who narators the crime seen and other deatils\n\nnarrator_instructions = \"\"\"You are trusted assistant and friend of the legendary detective Sherlock Holmes - Dr. John Watson.\nSherlock has just arrived at the seen of the murder.\nUse the provided details to give Sherlock a brief, engaging introduction to the crime seen in 100 words or less.\nYour tone should be conversational and should address Sherlock Holmes directly.\n\nCrime Scene Details:\n    Victim: {victim}\n    Time: {time}\n    Location: {location}\n    Weapon: {weapon}\n    Cause of Death: {cause}\n\n    Scene Description:\n    {scene}\n\"\"\"\n\ndef narrartor(state: GenerateGameState):\n    \"\"\"\n    Part of the Game Loop Graph.\n\n    Generates Dr. Watson's narration of the crime scene for Sherlock Holmes.\n\n    Args:\n        state (GenerateGameState): The LangGraph State object containing:\n            - story_details: Complete information about the crime\n\n    Returns:\n        dict: Contains the narration message. Adds to the State Object.\n            - messages: Dr. Watson's narrative description\n\n    Note:\n        - Provides a concise (100 words or less) introduction to the crime\n        - Maintains Dr. Watson's characteristic narrative style\n        - Sets the initial atmosphere for the investigation\n    \"\"\"\n    story = state['story_details']\n\n    # Format the message with the story details\n    system_message = narrator_instructions.format(\n        victim=story.victim_name,\n        time=story.time_of_death,\n        location=story.location_found,\n        weapon=story.murder_weapon,\n        cause=story.cause_of_death,\n        scene=story.crime_scene_details\n    )\n    # Generate narration\n    narration = llm.invoke([\n        SystemMessage(content=system_message),\n        HumanMessage(content=\"Create an atmospheric narration of the crime scene\")\n    ])\n\n    print_game_header()\n    print_narration(narration)\n\n    return {\"messages\": [narration]}\n\n# Node: User to select who to investigate\n\ndef sherlock(state: GenerateGameState):\n    \"\"\"\n    Part of the Game Loop Graph.\n\n    Handles the character selection phase of the investigation.\n\n    Args:\n        state (GenerateGameState): The LangGraph State object containing:\n            - characters: List of all character objects\n\n    Returns:\n        dict: Result of get_character_selection containing. Adds to the State Object.\n            - selected_character_id: Index of selected character or None for guessing phase\n\n    Note:\n        - Displays character list with randomized order\n        - Maintains mapping between display order and original character indices\n        - Prevents selection of the victim character\n    \"\"\"\n    characters = state['characters']\n\n    # Display characters and get the mapping of displayed order to original indices\n    display_to_original = print_characters_list(characters)\n\n    # Get user selection\n    return get_character_selection(characters, display_to_original)\n\n\n#Node: Allows the Users to guess the Killer\n\nKILLER_ROLE = \"Killer\"\n\ndef guesser(state: GenerateGameState):\n    \"\"\"\n    Part of the Game Loop Graph.\n\n    Manages the final phase where the player attempts to identify the killer.\n\n    Args:\n        state (GenerateGameState): The LangGraph State object containing:\n            - num_guesses_left: Number of remaining guess attempts\n            - characters: List of all character objects\n\n    Returns:\n        dict: Contains:\n            - result: \"end\" if game is over, \"sherlock\" to continue investigation\n            - num_guesses_left: Updated number of remaining guesses\n\n    Note:\n        - Handles the win/loss conditions\n        - Maintains guess counter\n        - Provides feedback on incorrect guesses\n        - Excludes victim from suspect list\n    \"\"\"\n    console = Console()\n    num_guesses_left = state['num_guesses_left']\n    all_characters = state['characters']\n    non_victims = [char for char in all_characters if char.role != 'Victim']\n    killer_character = next(char for char in all_characters if char.role == KILLER_ROLE)\n    characters = list(sorted(non_victims, key=lambda x: x.name))\n\n    # Print initial state\n    console.rule(\"[bold red]üîç Final Deduction[/bold red]\")\n    print_guesses_remaining(num_guesses_left)\n    print_suspect_list(characters)\n\n    is_win, is_lose = False, False\n\n    while True:\n        try:\n            # Get user input\n            choice = Prompt.ask(\n                \"\\n[bold red]Who is the killer?[/bold red] (Enter suspect number)\",\n                default=\"\",\n                show_default=False\n            )\n\n            choice = int(choice)\n            if 0 < choice <= len(characters):\n                selected_character_id = choice - 1\n                selected_character = characters[selected_character_id]\n\n                if selected_character.role == KILLER_ROLE:\n                    is_win = True\n                    break\n                else:\n                    print_incorrect_guess()\n                    num_guesses_left -= 1\n                    if num_guesses_left > 0:\n                        print_guesses_remaining(num_guesses_left)\n\n                if num_guesses_left == 0:\n                    is_lose = True\n                    break\n\n            else:\n                console.print(\"[red]Invalid input. Please enter a valid suspect number.[/red]\")\n        except ValueError:\n            console.print(\"[red]Invalid input. Please enter a number.[/red]\")\n\n    # Print final result\n    print_result(is_win, is_lose, killer_character.name)\n\n    is_end = is_win or is_lose\n    return {\"result\": \"end\", \"num_guesses_left\": num_guesses_left} if is_end else {\"result\": \"sherlock\", \"num_guesses_left\": num_guesses_left}\n\n\n# Node: Adding the Conversation SubGraph i.e. Conversation Loop\n\ndef conversation(state: GenerateGameState):\n    \"\"\"\n    Part of the Game Loop Graph.\n\n    Manages the main conversation loop between Sherlock/player and characters.\n\n    Args:\n        state (GenerateGameState): The LangGraph State object containing:\n            - selected_character_id: ID of the character to converse with\n            - characters: List of all character objects\n            - story_details: Complete story information\n\n    Returns:\n        dict: Contains either:\n            - messages: List of conversation messages if character selected\n            - END constant if no character selected (moving to guessing phase)\n\n    Note:\n        - Implements recursion limit to prevent infinite loops\n        - Handles conversation flow and state management\n        - Integrates with the conversation subgraph\n    \"\"\"\n    selected_character_id = state['selected_character_id']\n    if selected_character_id is not None:\n        characters = state['characters']\n        character = characters[selected_character_id]\n        inputs = {\n            \"character\": character,\n            \"story_details\": state['story_details'],\n        }\n        response = conversation_graph.invoke(inputs,{\"recursion_limit\": 50})\n\n        # Return the response as a message\n        return {\"messages\": [response['messages']]}\n    else:\n        return END","x":1930,"y":2920,"width":1007,"height":587},
		{"id":"be9144665ba08095","type":"text","text":"# Classes to define the Game Characters and allow for Structured Output from the LLMs while generating the Characters\nclass Character(BaseModel):\n    role: str = Field(\n        description=\"Primary role of the character in the story\",\n    )\n    name: str = Field(\n        description=\"Name of the character.\"\n    )\n    backstory: str = Field(\n        description=\"Backstory of the character focus, concerns, and motives.\",\n    )\n    @property\n    def persona(self) -> str:\n        return f\"Name: {self.name}\\nRole: {self.role}\\nBackstory: {self.backstory}\\n\"\n\nclass NPC(BaseModel):\n    characters: List[Character] = Field(\n        description=\"Comprehensive list of characters with their roles and backstories.\",\n        default_factory=list\n    )\n\n# A Class to define the Game Story and allow for Structured Output from the LLMs while generating the Game Story\nclass StoryDetails(BaseModel):\n    victim_name: str = Field(\n        description=\"Name of the murder victim\"\n    )\n    time_of_death: str = Field(\n        description=\"Approximate time when the murder occurred\"\n    )\n    location_found: str = Field(\n        description=\"Where the body was discovered\"\n    )\n    murder_weapon: str = Field(\n        description=\"The weapon or method used in the murder\"\n    )\n    cause_of_death: str = Field(\n        description=\"Specific medical cause of death\"\n    )\n    crime_scene_details: str = Field(\n        description=\"Description of the crime scene and any relevant evidence found\"\n    )\n    witnesses: str = Field(\n        description=\"Information about potential witnesses or last known sightings\"\n    )\n    initial_clues: str = Field(\n        description=\"Initial clues or evidence found at the scene\"\n    )\n    npc_brief:str = Field(\n        description=\"Brief description of the characters and their relationships\"\n    )\n\n# A Class to define and manage the State for the conversation\nclass ConversationState(TypedDict):\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n    character: Character # Character being interviewed\n    story_details: Optional[StoryDetails]  # Details about the murder mystery\n\n# A Class to define and manage the overall State of the Game\nclass GenerateGameState(TypedDict):\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n    environment: str  # Story environment\n    max_characters: int  # Number of characters\n    characters: List[Character]  # Characters in the story\n    story_details: Optional[StoryDetails]  # Details about the murder mystery\n    selected_character_id: Optional[int] # Index of the selected character\n    num_guesses_left: int # Number of guesses the player has\n    result: str #Store the Guesser result and evalute Correct/Incorrect","x":1280,"y":2920,"width":495,"height":587},
		{"id":"3e5aea3ef6e806b5","type":"file","file":"Documentation/images/Pasted image 20250108123428.png","x":880,"y":3214,"width":370,"height":619},
		{"id":"c90413e36e1a4f79","type":"text","text":"# sherlock","x":3260,"y":1960,"width":320,"height":80},
		{"id":"3a1e9ba567007700","type":"text","text":"# narrator \n[[./LLM/Prompts/NarratorPrompt]]","x":3260,"y":1820,"width":320,"height":80},
		{"id":"44f4f261a3808a5c","type":"text","text":"# guesser","x":3830,"y":2120,"width":320,"height":60},
		{"id":"d7b0ce9a8204f253","type":"text","text":"# END","x":3830,"y":2360,"width":320,"height":80},
		{"id":"b4281590d8e0c0cc","type":"text","text":"# Day End","x":3660,"y":1900,"width":195,"height":60},
		{"id":"13f9a6adc894b2de","type":"file","file":"Documentation/datamodel/Conversation Sub-Graph Construction.md","x":2234,"y":3640,"width":400,"height":400},
		{"id":"ff9d5c64723eb2d0","type":"text","text":"## IsFirstContact","x":2783,"y":2180,"width":229,"height":60},
		{"id":"8ff29a8cba5aa5b5","type":"text","text":"## character_greeting","x":2918,"y":2360,"width":323,"height":60},
		{"id":"42e2f0e113c8445c","type":"text","text":"## ask_question","x":2772,"y":2500,"width":250,"height":60},
		{"id":"6ded4b3cbff24f66","type":"text","text":"## end_conversation","x":2918,"y":2648,"width":277,"height":60},
		{"id":"78a1e3263999b32f","type":"text","text":"## get char data","x":4096,"y":1328,"width":250,"height":60},
		{"id":"6e2ca042f68415ba","type":"text","text":"## get story data","x":4096,"y":1420,"width":250,"height":60},
		{"id":"7701e7bff16e4930","type":"text","text":"## Player Gender?","x":3741,"y":1240,"width":250,"height":50},
		{"id":"e7f4e6e86883acb8","type":"text","text":"## Player Name?","x":3741,"y":1341,"width":250,"height":50},
		{"id":"f6fea929d600838c","type":"text","text":"## Player College Major?","x":3708,"y":1442,"width":315,"height":50},
		{"id":"36b764560848c932","type":"text","text":"## Property Buyback Deadline?","x":3668,"y":1543,"width":395,"height":50},
		{"id":"9f704a96651e353c","type":"text","text":"# Day Start","x":3660,"y":1820,"width":195,"height":60},
		{"id":"aea7d24f8c79befe","type":"text","text":"### Player Data Summary Game Settings Summary\n Confirm?","x":3681,"y":1645,"width":370,"height":115}
	],
	"edges":[
		{"id":"ee82db440f129961","fromNode":"925850244acc96de","fromSide":"left","toNode":"9645cd0feeca9769","toSide":"right","color":"6"},
		{"id":"03c0d4d0351577b4","fromNode":"925850244acc96de","fromSide":"left","toNode":"f2ce817f7d75bdc4","toSide":"right","color":"6"},
		{"id":"025e33dd7b7d8e16","fromNode":"139aa690cd4a1252","fromSide":"left","toNode":"9645cd0feeca9769","toSide":"right","color":"6"},
		{"id":"dfbf202b2fd960e8","fromNode":"925850244acc96de","fromSide":"left","toNode":"139aa690cd4a1252","toSide":"right","color":"6"},
		{"id":"554e11108d4d3e61","fromNode":"7ccdb3f8a5f0ca04","fromSide":"left","toNode":"139aa690cd4a1252","toSide":"right","color":"3"},
		{"id":"35b1af1e48699ffe","fromNode":"7ccdb3f8a5f0ca04","fromSide":"left","toNode":"925850244acc96de","toSide":"right","color":"3"},
		{"id":"c0cc11c80fe9e2f9","fromNode":"7ccdb3f8a5f0ca04","fromSide":"left","toNode":"ea76984f504e1097","toSide":"right","color":"3"},
		{"id":"90e40d3f2dcd8e5a","fromNode":"741091ae3f876bf1","fromSide":"bottom","toNode":"75800cb581207bb6","toSide":"top","color":"#a70eaa"},
		{"id":"f2247c2f7a931740","fromNode":"75800cb581207bb6","fromSide":"top","toNode":"741091ae3f876bf1","toSide":"bottom","color":"#a60ea9"},
		{"id":"37d5e02ec9095735","fromNode":"7ccdb3f8a5f0ca04","fromSide":"left","toNode":"741091ae3f876bf1","toSide":"right","color":"3"},
		{"id":"b227d8d8e478701c","fromNode":"7ccdb3f8a5f0ca04","fromSide":"left","toNode":"75800cb581207bb6","toSide":"right","color":"3"},
		{"id":"e58f92c432adc4f8","fromNode":"139aa690cd4a1252","fromSide":"right","toNode":"ea76984f504e1097","toSide":"left","color":"6"},
		{"id":"7e6845fce271d35c","fromNode":"925850244acc96de","fromSide":"right","toNode":"741091ae3f876bf1","toSide":"left","color":"6"},
		{"id":"33889465ccec3c17","fromNode":"925850244acc96de","fromSide":"bottom","toNode":"741091ae3f876bf1","toSide":"left","color":"5"},
		{"id":"ab4daa5b9cb775ad","fromNode":"9634ae7be44339cb","fromSide":"left","toNode":"9645cd0feeca9769","toSide":"right","color":"4"},
		{"id":"5f24ff9041f7945c","fromNode":"98ce9de560ab2ec0","fromSide":"left","toNode":"9634ae7be44339cb","toSide":"right","color":"4"},
		{"id":"7be8c9591d10c9c8","fromNode":"31cb95565d2f96e7","fromSide":"left","toNode":"98ce9de560ab2ec0","toSide":"right","color":"4"},
		{"id":"3e089281effa36d4","fromNode":"7ccdb3f8a5f0ca04","fromSide":"left","toNode":"31cb95565d2f96e7","toSide":"right","color":"3"},
		{"id":"f7b0b7d84dab6b77","fromNode":"9091c222ea3b26e1","fromSide":"left","toNode":"9db3c7850f2f3f6c","toSide":"right","color":"2"},
		{"id":"8afb9ba41dc865dd","fromNode":"9db3c7850f2f3f6c","fromSide":"left","toNode":"9645cd0feeca9769","toSide":"right","color":"2"},
		{"id":"4df865536367c8d8","fromNode":"7ccdb3f8a5f0ca04","fromSide":"left","toNode":"9091c222ea3b26e1","toSide":"right","color":"3"},
		{"id":"fe09397a2486c5ed","fromNode":"be9144665ba08095","fromSide":"right","toNode":"800ec800cec8c644","toSide":"left"},
		{"id":"df04fff6b545f708","fromNode":"800ec800cec8c644","fromSide":"bottom","toNode":"13f9a6adc894b2de","toSide":"top"},
		{"id":"9521bc1110ac6337","fromNode":"881bc99aa1283590","fromSide":"bottom","toNode":"9fcd4bf58f58594a","toSide":"top"},
		{"id":"04d6b2b67e1d9645","fromNode":"9fcd4bf58f58594a","fromSide":"bottom","toNode":"63cd1551b0cd7638","toSide":"top"},
		{"id":"5a397350835e60cd","fromNode":"c90413e36e1a4f79","fromSide":"bottom","toNode":"44f4f261a3808a5c","toSide":"left","label":"end talks"},
		{"id":"4cb8c72ae970b0d7","fromNode":"44f4f261a3808a5c","fromSide":"top","toNode":"c90413e36e1a4f79","toSide":"right"},
		{"id":"bc0cf40d7ba48a36","fromNode":"63cd1551b0cd7638","fromSide":"bottom","toNode":"3a1e9ba567007700","toSide":"top"},
		{"id":"38ef6282872e6874","fromNode":"3a1e9ba567007700","fromSide":"bottom","toNode":"c90413e36e1a4f79","toSide":"top"},
		{"id":"4afae95cb3137fd2","fromNode":"6893222499260c20","fromSide":"right","toNode":"63cd1551b0cd7638","toSide":"left"},
		{"id":"5ad608be6e2f6525","fromNode":"1b4a976f2556696c","fromSide":"right","toNode":"9fcd4bf58f58594a","toSide":"left"},
		{"id":"abb72a83adf9e39c","fromNode":"44f4f261a3808a5c","fromSide":"bottom","toNode":"d7b0ce9a8204f253","toSide":"top"},
		{"id":"3f41f7e628d04c2f","fromNode":"ff9d5c64723eb2d0","fromSide":"bottom","toNode":"373c6dfa18143497","toSide":"top","color":"4","label":"yes"},
		{"id":"f28153fa5bf0d383","fromNode":"0252b6649a74bb14","fromSide":"bottom","toNode":"ff9d5c64723eb2d0","toSide":"top"},
		{"id":"db7ca2055a4d1ff5","fromNode":"ff9d5c64723eb2d0","fromSide":"bottom","toNode":"8ff29a8cba5aa5b5","toSide":"top","color":"1","label":"no"},
		{"id":"57f60127068f0334","fromNode":"373c6dfa18143497","fromSide":"bottom","toNode":"42e2f0e113c8445c","toSide":"top"},
		{"id":"6a8b5ae1da50d699","fromNode":"8ff29a8cba5aa5b5","fromSide":"bottom","toNode":"42e2f0e113c8445c","toSide":"top"},
		{"id":"4deaf6a965b6d026","fromNode":"42e2f0e113c8445c","fromSide":"left","toNode":"f8904898612db66b","toSide":"left","label":"continue"},
		{"id":"b7cd4b1db270b1e1","fromNode":"f8904898612db66b","fromSide":"top","toNode":"42e2f0e113c8445c","toSide":"bottom"},
		{"id":"bd08f5684be4f2a7","fromNode":"42e2f0e113c8445c","fromSide":"right","toNode":"6ded4b3cbff24f66","toSide":"top","label":"end"},
		{"id":"49592a2222c2f445","fromNode":"c90413e36e1a4f79","fromSide":"left","toNode":"0252b6649a74bb14","toSide":"top"},
		{"id":"fa560092879f6ec7","fromNode":"6ded4b3cbff24f66","fromSide":"right","toNode":"c90413e36e1a4f79","toSide":"bottom","color":"#f0f0f0"},
		{"id":"d70a4d11c682815b","fromNode":"7701e7bff16e4930","fromSide":"bottom","toNode":"e7f4e6e86883acb8","toSide":"top"},
		{"id":"9f0163796bba3134","fromNode":"e7f4e6e86883acb8","fromSide":"bottom","toNode":"f6fea929d600838c","toSide":"top"},
		{"id":"ffac0b4610905e8f","fromNode":"f6fea929d600838c","fromSide":"bottom","toNode":"36b764560848c932","toSide":"top"},
		{"id":"0ff3dfd3824a8d6c","fromNode":"36b764560848c932","fromSide":"bottom","toNode":"aea7d24f8c79befe","toSide":"top"}
	]
}